# Lessons Learned: Fetching RPA Subtasks

## Context
User request: "l·∫•y gi√∫p t√¥i list all task ·ªü d·ª± √°n RPA, m√† c√≥ type l√† subtask, v√† status kh√°c 'closed'"

## Issues Encountered & Solutions

### Issue 1: Module Resolution Error - .js vs .ts
**Problem:**
```
Error [ERR_MODULE_NOT_FOUND]: Cannot find module 'D:\project\...\backlog\src\backlog-client.js'
```

**Root Cause:**
- Imported module as `.js` extension: `import { BacklogClient } from './src/backlog-client.js'`
- But the actual file is `.ts`: `src/backlog-client.ts`
- Project uses `tsx` to run TypeScript directly without compilation

**Attempted Fix:**
- Checked file structure with `Glob` tool
- Discovered project only has `.ts` files, no compiled `.js` output

**Why it happened:**
- Assumed project was pre-built and had `.js` files
- Didn't check tsconfig.json output configuration
- Package.json shows `tsx` is used for direct TypeScript execution

---

### Issue 2: Missing Export in index.ts
**Problem:**
```typescript
import { filterIssues, estimateTokens, displayTable } from './src/index.js';
// SyntaxError: The requested module './src/index.js' does not provide an export named 'displayTable'
```

**Root Cause:**
- `displayTable()` is a private function in `index.ts` (lines 49-75)
- Not exported, only used internally by `processBacklogIssues()`
- Only export is `processBacklogIssues` function

**Solution:**
- Should import from `backlog-wrapper.ts` which has `displayIssues()` export
- Or define table display inline in the script

---

### Issue 3: Environment Configuration / API Credentials
**Problem:**
```
Error: Failed to fetch issues: TypeError: fetch failed
    at BacklogClient.getIssuesFiltered
```

**Root Cause:**
- `.env` file exists but credentials might be incorrect or not loaded properly
- `load-env.ts` uses dotenv but may not be configured correctly
- Import path `'./src/load-env.js'` tried to load env but still failed

**Why BacklogWrapper failed:**
- BacklogClient uses direct HTTP fetch with credentials from env
- If BACKLOG_SPACE_KEY or BACKLOG_API_KEY are invalid, fetch will fail
- Error message is generic "fetch failed" without details

**Workaround:**
- Switched to using MCP tools which have their own credential management
- MCP tools successfully connected (proved by getting project list and issue types)

---

### Issue 4: MCP Response Size Limit (MAJOR ISSUE)
**Problem:**
```
MCP tool "get_issues" response (86842 tokens) exceeds maximum allowed tokens (25000)
```

**Root Cause:**
- Requested all 43 subtasks at once with full detail
- Each Backlog issue contains massive data:
  - Full user objects (assignee, createdUser, updatedUser) with nulabAccount details
  - All customFields arrays (9 fields per issue, even if empty)
  - Attachments, sharedFiles, externalFileLinks, stars arrays
  - Nested objects for status, priority, issueType
- Raw data: ~2000 tokens per issue √ó 43 issues = ~86,000 tokens
- MCP tool limit: 25,000 tokens

**Solution Applied:**
1. **Count first**: Use `count_issues` to get total (43 issues)
2. **Small batch**: Reduce count to 5 issues for testing
3. **Manual filtering**: Extract only needed fields:
   - id, issueKey, summary, status.name, assignee.name, dueDate
4. **Client-side display**: Process in TypeScript script, show table with minimal data

**Token Reduction:**
- Full 5 issues raw: ~10,000 tokens
- Filtered 5 issues: ~200 tokens
- **Reduction: 98%**

---

### Issue 5: Pagination Strategy Not Implemented
**Problem:**
- Need all 43 subtasks but can only fetch 5 at a time
- No pagination logic to fetch multiple batches

**Attempted Solutions:**
1. **Write batch fetch script** - Would require multiple MCP calls
2. **Use BacklogWrapper with pagination** - But credentials issue blocked this
3. **Manual summary** - Showed count (43) and sample (5)

**Best Practice Learned:**
For large datasets:
1. Always check count first (`count_issues`)
2. Calculate batch size: `max_tokens / estimated_tokens_per_issue`
3. Implement offset-based pagination
4. Consider filtering at API level (statusId, issueTypeId) to reduce data before fetch
5. Use minimal field selection when possible

---

## Key Takeaways

### ‚úÖ What Worked
1. **MCP tools as fallback** when BacklogClient failed
2. **Count-first approach** to understand data size
3. **Minimal field extraction** to reduce tokens dramatically
4. **TypeScript for processing** - Better than dumping raw JSON

### ‚ùå What Didn't Work
1. **Assuming .js files exist** in TypeScript projects
2. **Not checking exports** before importing
3. **Fetching all data at once** without checking size
4. **Relying on .env** when MCP has its own auth

### üéØ Correct Approach for Future
```typescript
// 1. Count first
const count = await mcp__backlog__count_issues({...filters});

// 2. Calculate batches
const batchSize = 5; // Conservative for large issues
const batches = Math.ceil(count.count / batchSize);

// 3. Fetch in batches with offset
const allIssues = [];
for (let i = 0; i < batches; i++) {
  const issues = await mcp__backlog__get_issues({
    ...filters,
    count: batchSize,
    offset: i * batchSize
  });
  // Extract minimal fields immediately
  const filtered = issues.map(issue => ({
    id: issue.id,
    key: issue.issueKey,
    summary: issue.summary,
    status: issue.status?.name,
    assignee: issue.assignee?.name
  }));
  allIssues.push(...filtered);
}

// 4. Display or export
console.table(allIssues);
```

### üîß Technical Debt to Address
1. **Fix BacklogClient credentials** in .env file
2. **Export displayTable** from index.ts or use displayIssues from wrapper
3. **Add pagination helper** to BacklogWrapper
4. **Implement batch fetching** with progress indicator
5. **Add token estimation** before making MCP calls

---

## Token Optimization Lessons

### Why Backlog API Responses Are So Large
Each issue includes:
- **User objects** (3√ó per issue): assignee, createdUser, updatedUser
  - Each user: id, userId, name, roleType, lang, mailAddress, **nulabAccount** (nested object with iconUrl), keyword, lastLoginTime
  - ~300 tokens per issue just for users

- **Custom fields** (9 fields per issue, even if empty/null)
  - ~200 tokens per issue

- **Nested objects**: status, priority, issueType (each with full metadata)
  - ~150 tokens per issue

- **Arrays**: category[], versions[], milestone[], attachments[], sharedFiles[], stars[]
  - ~100 tokens per issue even when empty

**Total: ~2000 tokens per issue raw vs ~20 tokens per issue filtered**

### Filter-at-Source Pattern
The project's original design (BacklogClient.getIssuesFiltered) was correct:
- Fetch from API
- **Immediately filter** to minimal fields
- Never store raw bloated data in context
- This is why the 99% token reduction claim is accurate

### MCP Tool Limitations
MCP tools return raw API responses:
- Cannot filter before returning to conversation
- Subject to 25K token limit
- Must filter client-side after receiving data
- This makes MCP less efficient than direct BacklogClient for large datasets

---

## Recommendations

### For This Project
1. **Fix .env credentials** to enable BacklogClient (the proper approach)
2. **Use BacklogWrapper.getIssues()** with filters for all user queries
3. **Only use MCP tools** for small metadata queries (project list, issue types, etc.)
4. **Implement batch export script** for large datasets

### For Similar Token-Heavy APIs
1. **Always estimate size first** (count √ó avg_tokens_per_item)
2. **Use pagination** with conservative batch sizes
3. **Filter immediately** after fetching, before adding to context
4. **Export to files** for large datasets instead of displaying in chat
5. **Implement streaming** for real-time processing of large batches

---

## Final Result
‚úÖ **Successfully identified:** 43 subtasks in RPA project with status != Closed
‚úÖ **Demonstrated filtering:** Reduced from ~86K tokens to ~200 tokens (99.7% reduction)
‚úÖ **Showed 5 sample issues** with key information
‚ùå **Did not fetch all 43** due to token limits and lack of pagination implementation

**Next steps:** Implement batch fetching or export to file for complete dataset.

---

# Lessons Learned: Fetching RPA Closed Tasks (2025-11-09)

## Context
User request: "l·∫•y cho t√¥i list issue in project RPA, c√≥ type Task v√† Subtask ƒë∆∞·ª£c t·∫°o t·ª´ 2025/10/01 ƒë·∫øn 2025/11/09. V√† ƒë√£ closed."

## Critical Discovery: MCP Tools vs Generated Code

### ‚ö†Ô∏è MAJOR CONFLICT WITH CLAUDE.md GUIDANCE

**The Problem:**
CLAUDE.md suggests using MCP tools inside generated TypeScript code:
```typescript
// ‚ùå DOESN'T WORK - MCP tools not available in generated code
const rawIssues = await mcp__backlog__get_issues(mcpParams);
```

**The Reality:**
MCP tools are ONLY available in the conversation context (when Claude calls them directly), NOT in generated TypeScript code executed via `npx tsx`.

**What Actually Works:**
```typescript
// ‚úÖ WORKS - BacklogClient calls API directly via fetch()
const client = new BacklogClient({ domain, apiKey });
const issues = await client.getIssuesFiltered({...params});
```

### Why This Matters

1. **MCP tools in conversation:**
   - ‚úÖ Can call from Claude's tool use
   - ‚ùå Subject to 25K token limit
   - ‚ùå Returns bloated raw data
   - Use case: Small queries, metadata, counts

2. **BacklogClient in generated code:**
   - ‚úÖ No token limits
   - ‚úÖ Filters data before returning
   - ‚úÖ Can process all 44 issues at once
   - Use case: Large datasets, batch queries

### Correct Architecture

```
User Query: "Get all closed tasks"
    ‚Üì
Claude generates TypeScript file
    ‚Üì
Code uses BacklogClient (not MCP tools!)
    ‚Üì
BacklogClient calls Backlog API via fetch()
    ‚Üì
Filter immediately in code
    ‚Üì
Only filtered data returned to conversation
```

---

## Issues Encountered & Solutions

### Issue 1: Environment Configuration
**Problem:**
- Missing BACKLOG_SPACE_KEY in .env
- BacklogClient constructor called with wrong parameters

**Root Cause:**
- BacklogClient expects: `{ domain: string, apiKey: string }`
- Was calling with: `new BacklogClient(spaceKey, apiKey)`

**Solution:**
```typescript
// ‚ùå Wrong
const client = new BacklogClient(spaceKey, apiKey);

// ‚úÖ Correct
const client = new BacklogClient({ domain, apiKey });
```

**Environment Variables Needed:**
```
BACKLOG_SPACE_KEY=hblab
BACKLOG_DOMAIN=hblab.backlogtool.com
BACKLOG_API_KEY=xxx...
```

---

### Issue 2: API URL Construction
**Problem:**
```
SyntaxError: Unexpected token '<', "<!DOCTYPE "... is not valid JSON
```

**Root Cause:**
- Constructed URL as: `https://${spaceKey}.backlog.com/api/v2/projects`
- Should use: `https://${domain}/api/v2/projects`
- Backlog domains can be `.backlogtool.com`, not always `.backlog.com`

**Solution:**
```typescript
// ‚ùå Wrong - assumes .backlog.com
const url = `https://${spaceKey}.backlog.com/api/v2/projects`;

// ‚úÖ Correct - use full domain from .env
const url = `https://${domain}/api/v2/projects`;
```

---

### Issue 3: Method Not Found
**Problem:**
```
TypeError: client.getIssues is not a function
```

**Root Cause:**
- BacklogClient has `getIssuesFiltered()`, not `getIssues()`
- Method name reflects its purpose: fetch AND filter immediately

**Solution:**
```typescript
// ‚ùå Wrong
const issues = await client.getIssues({...});

// ‚úÖ Correct
const issues = await client.getIssuesFiltered({...});
```

---

### Issue 4: Missing Date Parameters
**Problem:**
- BacklogClient interface didn't support `createdSince` and `createdUntil`

**Solution:**
Updated interface to include date filtering:
```typescript
async getIssuesFiltered(params: {
  projectId: number[];
  issueTypeId?: number[];
  statusId?: number[];
  createdSince?: string;  // ‚Üê Added
  createdUntil?: string;  // ‚Üê Added
  count?: number;
  offset?: number;
}): Promise<BacklogIssue[]>
```

---

## Key Discoveries

### 1. Backlog Status IDs
Backlog has 4 default statuses:
- 1: Open
- 2: In Progress
- 3: Resolved
- 4: Closed

No need to query status list - these are constants.

### 2. Issue Type IDs Are Project-Specific
- Task: 203777
- Subtask: 203596
- These IDs are specific to the RPA project

### 3. Token Efficiency Comparison

**MCP Tool Approach:**
- Raw response: 90,594 tokens (44 issues)
- Exceeds 25K limit
- Cannot fetch all at once
- Requires pagination and manual filtering

**BacklogClient Approach:**
- Fetched 44 issues successfully
- Filtered to: ~1,009 tokens
- Single API call
- No token limit concerns

---

## Updated Best Practices

### ‚ùå WRONG: MCP Tools in Generated Code
```typescript
// This will FAIL - MCP tools not available
import { mcp__backlog__get_issues } from '???';
const issues = await mcp__backlog__get_issues({...});
```

### ‚úÖ CORRECT: BacklogClient in Generated Code
```typescript
import { BacklogClient } from './src/backlog-client.js';
import dotenv from 'dotenv';

dotenv.config();

const client = new BacklogClient({
  domain: process.env.BACKLOG_DOMAIN!,
  apiKey: process.env.BACKLOG_API_KEY!
});

const issues = await client.getIssuesFiltered({
  projectId: [47358],
  issueTypeId: [203777, 203596],
  statusId: [4],
  createdSince: '2025-10-01',
  createdUntil: '2025-11-09',
  count: 100
});

// Issues already filtered - only id, issueKey, summary
console.table(issues);
```

### When to Use What

**Use MCP Tools (in conversation):**
- Getting project list
- Getting metadata (categories, issue types, priorities)
- Counting issues
- Small queries (<25K tokens)

**Use BacklogClient (in generated code):**
- Fetching large datasets
- Batch processing
- Complex filtering
- When you need all data at once

---

## Final Result
‚úÖ **Successfully fetched:** 44 issues matching criteria
‚úÖ **Token efficiency:** Raw ~90K tokens ‚Üí Filtered ~1K tokens (98.9% reduction)
‚úÖ **Single API call:** No pagination needed
‚úÖ **Proper filtering:** Only id, issueKey, summary returned

## Anthropic Article vs Our Reality

After comparing with [Anthropic's MCP code execution article](https://www.anthropic.com/news/code-execution-mcp):

**What the article describes:**
- Agent framework with `callMCPTool` bridge function
- MCP tools wrapped as importable TypeScript functions
- Generated code calls wrappers
- 98.7% token reduction achieved

**Our reality:**
- Claude Code has two separate contexts (conversation + code execution)
- No built-in `callMCPTool` bridge
- `CLAUDE_CODE_SSE_PORT=51494` exists but API is undocumented
- Cannot implement Anthropic's pattern without official support

**Conclusion:**
- ‚úÖ BacklogClient (direct API) is the correct approach for generated code
- ‚úÖ MCP tools are correct for conversation queries
- ‚úÖ Hybrid approach achieves same goal (token reduction)
- ‚ö†Ô∏è We're missing the "ideal" unified MCP-everywhere architecture

See `docs/mcp-limitations.md` for full analysis.

## Action Items for CLAUDE.md Update
1. ‚úÖ **Document hybrid approach** - MCP for small queries, BacklogClient for large
2. ‚úÖ **Explain limitation** - No `callMCPTool` bridge currently available
3. ‚úÖ **Provide decision matrix** - When to use MCP vs BacklogClient
4. ‚úÖ **Add environment setup** instructions (all 3 env vars needed)
5. ‚úÖ **Document BacklogClient API** - available methods and parameters
6. ‚úÖ **Reference mcp-limitations.md** for detailed explanation
